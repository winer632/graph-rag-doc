<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Graph-RAG 系统技术方案 (KAG Enhanced)</title>
    <!-- 引入 Mermaid 用于渲染图表 -->
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'neutral' });
    </script>
    <!-- 引入代码高亮样式 -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>

    <style>
        :root {
            --primary-color: #2563eb;
            --text-color: #1f2937;
            --bg-color: #ffffff;
            --sidebar-bg: #f3f4f6;
            --code-bg: #282c34;
            --border-color: #e5e7eb;
            --warning-bg: #fff7ed;
            --warning-border: #fdba74;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            margin: 0;
            display: flex;
            min-height: 100vh;
        }

        /* 侧边栏导航 */
        nav {
            width: 260px;
            background-color: var(--sidebar-bg);
            padding: 2rem 1rem;
            position: fixed;
            height: 100vh;
            overflow-y: auto;
            border-right: 1px solid var(--border-color);
            display: none; /* 移动端默认隐藏 */
        }

        nav ul {
            list-style: none;
            padding: 0;
        }

        nav li {
            margin-bottom: 0.8rem;
        }

        nav a {
            text-decoration: none;
            color: #4b5563;
            font-size: 0.95rem;
            transition: color 0.2s;
        }

        nav a:hover, nav a.active {
            color: var(--primary-color);
            font-weight: 600;
        }

        nav h3 {
            font-size: 0.85rem;
            text-transform: uppercase;
            color: #9ca3af;
            margin-bottom: 1rem;
            letter-spacing: 0.05em;
        }

        /* 主内容区 */
        main {
            flex: 1;
            padding: 2rem 4rem;
            max-width: 1000px;
            margin-left: 260px; /* 留出侧边栏宽度 */
        }

        h1 { font-size: 2.25rem; margin-bottom: 1.5rem; border-bottom: 1px solid var(--border-color); padding-bottom: 1rem; }
        h2 { font-size: 1.75rem; margin-top: 3rem; margin-bottom: 1rem; color: #111827; }
        h3 { font-size: 1.4rem; margin-top: 2rem; margin-bottom: 0.8rem; color: #374151; }
        h4 { font-size: 1.1rem; margin-top: 1.5rem; font-weight: 600; }

        p { margin-bottom: 1rem; }

        ul, ol { margin-bottom: 1rem; padding-left: 1.5rem; }
        li { margin-bottom: 0.5rem; }

        /* 代码块样式 */
        pre {
            background-color: var(--code-bg);
            border-radius: 8px;
            padding: 1rem;
            overflow-x: auto;
            margin: 1.5rem 0;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
        }
        
        code {
            font-family: "Fira Code", Consolas, Monaco, monospace;
            font-size: 0.9rem;
        }

        /* 引用块 */
        blockquote {
            border-left: 4px solid var(--primary-color);
            background-color: #eff6ff;
            margin: 1.5rem 0;
            padding: 1rem;
            border-radius: 0 8px 8px 0;
        }

        /* 警告/注意块 */
        .warning-box {
            border-left: 4px solid var(--warning-border);
            background-color: var(--warning-bg);
            padding: 1rem;
            margin: 1.5rem 0;
            border-radius: 0 8px 8px 0;
        }

        /* Mermaid 图表容器 */
        .mermaid-container {
            background: #fff;
            padding: 1rem;
            border: 1px solid var(--border-color);
            border-radius: 8px;
            margin: 2rem 0;
            text-align: center;
        }

        /* 响应式设计 */
        @media (min-width: 1024px) {
            nav { display: block; }
        }

        @media (max-width: 1023px) {
            main { margin-left: 0; padding: 1.5rem; }
            nav { display: none; }
        }
    </style>
</head>
<body>

    <!-- 侧边栏目录 -->
    <nav>
        <h3>目录</h3>
        <ul>
            <li><a href="#overview">1. 概述</a></li>
            <li><a href="#architecture">2. 总体架构图</a></li>
            <li><a href="#pipeline-data">3. 离线数据处理流程</a></li>
            <ul>
                <li><a href="#schema">3.1 Schema 定义 (Schema-First)</a></li>
                <li><a href="#parsing">3.2 文档解析与切分</a></li>
                <li><a href="#extraction">3.3 LLM 信息抽取</a></li>
                <li><a href="#normalization">3.4 实体归一化</a></li>
                <li><a href="#indexing">3.5 互索引构建 (Mutual Indexing)</a></li>
            </ul>
            <li><a href="#pipeline-query">4. 在线问答处理流程</a></li>
            <ul>
                <li><a href="#planning">4.1 逻辑规划 (Schema-Guided)</a></li>
                <li><a href="#reasoning">4.2 推理与检索</a></li>
            </ul>
            <li><a href="#analysis">5. 方案分析与差距对比</a></li>
        </ul>
    </nav>

    <!-- 主内容 -->
    <main>
        <header>
            <h1>Graph-RAG 系统技术方案 (KAG Enhanced)</h1>
            <p><strong>版本：</strong> v2.1 | <strong>状态：</strong> Draft | <strong>作者：</strong> 王欣鑫</p>
        </header>

        <section id="overview">
            <h2>1. 概述</h2>
            <p>本方案旨在构建一个结合知识图谱（Knowledge Graph, KG）与大语言模型（LLM）的工业级 RAG 系统。参考 <strong>OpenSPG/KAG</strong> 的设计理念，通过引入 <strong>Schema 约束</strong>、<strong>互索引机制</strong> 和 <strong>逻辑求解器</strong>，解决传统 RAG 在处理复杂逻辑、多跳推理及专业领域知识精度上的不足。</p>
            <blockquote>
                <strong>核心理念：</strong><br>
                • <strong>Schema-First：</strong> 预定义领域本体（实体/概念/事件），确保知识抽取的规范性。<br>
                • <strong>互索引 (Mutual Indexing)：</strong> 建立文本切片与图谱节点的双向映射，实现混合检索。<br>
                • <strong>逻辑求解：</strong> 将自然语言转化为逻辑计划，支持计算与推理，而非仅靠语义匹配。
            </blockquote>
        </section>

        <section id="architecture">
            <h2>2. 总体架构图</h2>
            <div class="mermaid-container">
                <div class="mermaid">
graph TD
    subgraph "离线数据处理流程 (Data Pipeline)"
        Init[Schema/Ontology 定义] --> A[原始文档 PDF/Word/MD]
        A --> B(文档解析 Parsing)
        B --> C(文本切分 Chunking)
        C --> D{LLM 信息抽取}
        D -->|基于 Schema| E[实体/概念/事件]
        D -->|提取关系| F[关系 Relation]
        E & F --> G(实体归一化 Normalization)
        G --> H(图谱构建 Graph Construction)
        H --> I[(图数据库 Neo4j)]
        C --> J[(向量/文本数据库)]
        I <-->|互索引 Mutual Indexing| J
    end

    subgraph "在线问答处理流程 (Query Pipeline)"
        U[用户提问] --> V(逻辑规划 Logic Planning)
        V --> W(推理与检索 Reasoning & Retrieval)
        W --> X(获取关联 Chunk 内容)
        X --> Y(上下文重组 Context Merge)
        Y --> Z(LLM 答案生成)
        Z --> Ans[最终回答]
    end
                </div>
            </div>
        </section>

        <section id="pipeline-data">
            <h2>3. 离线数据处理流程</h2>
            <p>此流程负责将非结构化数据转化为结构化知识并入库。与传统 Graph-RAG 不同，我们引入了 <strong>Schema-First</strong> 和 <strong>DIKW (Data-Information-Knowledge-Wisdom)</strong> 建模思想。</p>

            <h3 id="schema">3.1 Schema 定义 (Schema-First)</h3>
            <p>在解析文档前，必须定义领域的 Schema。这不仅是类型列表，更是对属性和逻辑的约束。</p>
            <pre><code class="language-python">class SchemaConfig:
    # 1. 实体 (Entity): 具体存在的对象
    ENTITIES = ['Person', 'Company', 'Product']
    
    # 2. 概念 (Concept): 抽象的分类或领域术语
    CONCEPTS = ['Industry', 'Technology', 'Regulation']
    
    # 3. 事件 (Event): 动态发生的动作，包含时间/地点
    EVENTS = ['Acquisition', 'Release', 'Lawsuit']
    
    # 4. 属性约束 (Properties): 定义每个类型必须包含的字段
    PROPERTIES = {
        'Company': ['revenue', 'employee_count', 'founded_date'],
        'Event': ['event_date', 'location', 'participants']
    }</code></pre>

            <h3 id="parsing">3.2 文档解析与切分 (Parsing & Chunking)</h3>
            <ul>
                <li><strong>输入：</strong> PDF, Word, Markdown, HTML 等格式文件。</li>
                <li><strong>处理逻辑：</strong>
                    <ol>
                        <li><strong>加载 (Loader)：</strong> 使用商汤科技的 autopdf 等工具转换为 Markdown。</li>
                        <li><strong>切分 (Splitter)：</strong> 采用混合切分策略（Markdown 结构化切分 + 递归字符切分），并对特殊内容（图片、代码块）进行保护。</li>
                        <li><strong>索引化：</strong> 生成唯一 <code>chunk_id</code>。</li>
                    </ol>
                </li>
            </ul>

            <h3 id="extraction">3.3 LLM 信息抽取 (LLM-based Extraction)</h3>
            <p>利用 LLM 进行抽取时，将 Schema 定义注入 Prompt，强制 LLM 输出符合规范的结构化数据，并显式区分实体、概念和事件。</p>
            
            <pre><code class="language-python">def extract_knowledge_from_chunk(text_chunk, schema_config):
    """
    基于 Schema 的知识抽取
    """
    system_prompt = f"""
    你是一个领域知识图谱构建专家。请根据以下 Schema 定义从文本中提取知识。
    
    【Schema 定义】
    - 实体类型: {schema_config.ENTITIES}
    - 概念类型: {schema_config.CONCEPTS}
    - 事件类型: {schema_config.EVENTS} (注意提取时间 event_date)
    - 属性约束: {schema_config.PROPERTIES}
    
    【输出要求】
    1. 严格遵守类型定义，不要创造 Schema 之外的类型。
    2. 对于事件，必须提取时间要素，以便构建时序关系。
    3. 输出格式为 JSON。
    """
    
    # 调用 LLM 执行抽取
    return call_llm(system_prompt, text_chunk)</code></pre>

            <h3 id="normalization">3.4 实体归一化 (Normalization)</h3>
            <p>采用多级漏斗机制：<strong>字面匹配 -> 语义相似度 -> LLM 深度裁决</strong>，解决多源数据融合问题。</p>
            <pre><code class="language-python">def is_same_entity(new_node, existing_node):
    # 1. 极速通道：字面完全一致
    if new_node.name == existing_node.name: return True
    
    # 2. 向量相似度检查
    sim = cosine_similarity(new_node.embedding, existing_node.embedding)
    if sim < 0.6: return False # 快速拒绝
    
    # 3. LLM 深度裁决 (处理别名、全称简称、版本号等复杂情况)
    if sim > 0.92: return True # 快速通过
    
    return llm_judge(new_node, existing_node)</code></pre>

            <h3 id="indexing">3.5 互索引构建 (Mutual Indexing)</h3>
            <p>这是 KAG 架构的核心。我们需要建立向量索引与图谱索引的双向映射，以支持混合检索。为了保证数据一致性，采用<strong>“处理完再入库”</strong>的流水线模式。</p>
            
            <div class="mermaid-container">
                <div class="mermaid">
sequenceDiagram
    participant Doc as 文档处理
    participant LLM as LLM抽取
    participant Norm as 归一化模块
    participant GraphDB as 图数据库(Neo4j)
    participant VectorDB as 向量数据库
    
    Doc->>Doc: 1. 切分文档，生成 chunk_id (UUID)
    Doc->>LLM: 2. 输入 Chunk 文本
    LLM-->>Doc: 返回实体提及 (Mentions: "A公司")
    
    Doc->>Norm: 3. 请求归一化 ("A公司")
    Norm->>GraphDB: 查询/创建实体 ID
    GraphDB-->>Norm: 返回 entity_id (Company:1001)
    Norm-->>Doc: 返回 ID 列表 [Company:1001]
    
    par 并行写入 (双写)
        Doc->>GraphDB: 4. 写图谱: 节点 Company:1001 关联 source_chunk_id
        Doc->>VectorDB: 5. 写向量: Chunk 向量 + Metadata {related_ids: [Company:1001]}
    end
                </div>
            </div>
        </section>

        <section id="pipeline-query">
            <h2>4. 在线问答处理流程</h2>
            <p>从传统的“关键词匹配”升级为“逻辑求解器 (Solver)”。</p>

            <h3 id="planning">4.1 逻辑规划 (Schema-Guided Logic Planning)</h3>
            <p>利用 <strong>Schema 约束</strong> 和 <strong>KG-Solver</strong>，将自然语言转化为可执行的 <strong>KGDSL (领域特定语言)</strong>，并通过校验机制保证稳定性。</p>
            
            <h4>处理流程：</h4>
            <ol>
                <li><strong>实体链接 (Grounding)：</strong> 首先将问题中的“A公司”映射为图谱中的唯一 ID <code>Company:1001</code>，而非仅靠文本生成。</li>
                <li><strong>Schema 约束生成：</strong> 将领域 Schema（如 Company 有 revenue 属性）注入 Prompt，限制 LLM 只能生成合法的属性名。</li>
                <li><strong>DSL 生成：</strong> 生成标准化的查询语句。</li>
            </ol>

            <h4>示例：</h4>
            <ul>
                <li><strong>输入：</strong> "A公司2023年的营收相比2022年增长了多少？"</li>
                <li><strong>输出计划 (KGDSL 伪代码)：</strong></li>
            </ul>
            <pre><code class="language-text">// 1. 实体锚定 (由 Entity Linking 模块完成，非 LLM 生成)
$e = Entity(type="Company", id="1001") 

// 2. 属性获取 (Schema 约束 LLM 生成)
$val1 = $e.get_property("revenue", date="2023")
$val2 = $e.get_property("revenue", date="2022")

// 3. 逻辑计算 (Solver 内置算子)
Return Calculate(($val1 - $val2) / $val2)</code></pre>

            <h4>实体链接实现逻辑 (伪代码)：</h4>
            <pre><code class="language-python">class EntityLinker:
    def __init__(self, vector_db, graph_db, llm):
        self.vector_db = vector_db # 存储实体名的向量
        self.graph_db = graph_db   # 存储图谱结构
        self.llm = llm

    def link(self, user_query: str, target_types: list = None) -> str:
        """
        输入：用户Query
        输出：图谱中的唯一 Entity ID
        """
        # 1. [NER] 提取指称项 (Mention)
        mention = self.extract_mention(user_query) # e.g., "A公司"
        
        # 2. [Recall] 混合召回候选集
        candidates = []
        # 2.1 向量召回 (处理别名/简称)
        candidates.extend(self.vector_db.search(mention, top_k=5))
        # 2.2 倒排索引召回 (处理精确匹配/字面相似)
        candidates.extend(self.graph_db.keyword_search(mention, top_k=5))
        
        # 3. [Filter] 类型过滤
        if target_types:
            candidates = [c for c in candidates if c.type in target_types]

        # 4. [Rank] 实体消歧 (LLM 裁决)
        if len(candidates) == 1 or candidates[0].score > 0.95:
            return candidates[0].id
            
        return self.llm_disambiguate(user_query, candidates)</code></pre>

            <h3 id="reasoning">4.2 推理与检索 (Reasoning & Retrieval)</h3>
            <p>执行逻辑计划，结合图谱遍历与向量检索。</p>
            <ol>
                <li><strong>锚点定位 (Anchor Retrieval)：</strong>
                    <ul>
                        <li>如果实体明确，直接在图谱中定位。</li>
                        <li>如果实体模糊，先通过向量检索找到 Top-K Chunks，提取其中的实体作为图谱推理的“锚点”。</li>
                    </ul>
                </li>
                <li><strong>多跳推理与计算：</strong>
                    <ul>
                        <li>执行图谱遍历（Traversal）获取多跳关系。</li>
                        <li>执行属性过滤（Filtering）和数值计算（Calculation）。</li>
                    </ul>
                </li>
                <li><strong>上下文召回：</strong> 根据推理路径上的节点，通过互索引召回对应的原始文本 Chunk。</li>
            </ol>
        </section>

        <section id="analysis">
            <h2>5. 方案分析与差距对比</h2>
            
            <h3>5.1 核心优势 (KAG 增强)</h3>
            <ul>
                <li><strong>逻辑可解释：</strong> 通过 Solver 机制，能够处理数值计算和逻辑推理问题，而非仅靠概率生成。</li>
                <li><strong>知识精度高：</strong> Schema-First 机制保证了知识抽取的规范性，减少了脏数据。</li>
                <li><strong>混合检索能力：</strong> 互索引机制解决了“有图无文”或“有文无图”的割裂问题。</li>
                <li><strong>时序感知：</strong> 事件类型的引入使得系统具备了处理时间线问题的能力。</li>
            </ul>

            <div class="warning-box">
                <h3>5.2 与原生 KAG/OpenSPG 的差距分析</h3>
                <p>本方案是一个轻量级的 KAG 实现，但在以下方面与原生 OpenSPG 引擎存在差距：</p>
                
                <h4>缺失 SPG 的“可编程性” (The "Programmable" in SPG)</h4>
                <ul>
                    <li><strong>KAG/OpenSPG 原生能力：</strong> SPG 不仅仅是定义属性，它允许在 Schema 中<strong>直接定义逻辑规则</strong>。
                        <br><em>例子：</em> 可以在 Schema 中定义规则：<code>如果 A 持股 B > 50%，则 A 控制 B</code>。当数据写入时，SPG 引擎会自动推理出“控制”关系，而不需要在查询时临时计算。</li>
                    <li><strong>本方案设计：</strong> 目前的 Schema (3.1) 主要是静态的类型和属性定义（Python Class），缺少了嵌入 Schema 的动态逻辑规则。</li>
                    <li><strong>影响：</strong> 对于极其复杂的隐式关系推理，本方案需要在查询阶段（Query Time）做更多工作，而 SPG 是在写入阶段（Write Time）或预计算阶段完成，查询效率更高。</li>
                </ul>
            </div>
        </section>

        <footer>
            <p style="text-align: center; margin-top: 4rem; color: #6b7280; font-size: 0.9rem;">
                Generated for Graph-RAG Implementation Guide (KAG Enhanced)
            </p>
        </footer>
    </main>

</body>
</html>
