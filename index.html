<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Graph-RAG 系统技术方案--王欣鑫</title>
    <!-- 引入 Mermaid 用于渲染图表 -->
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'neutral' });
    </script>
    <!-- 引入代码高亮样式 -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>

    <style>
        :root {
            --primary-color: #2563eb;
            --text-color: #1f2937;
            --bg-color: #ffffff;
            --sidebar-bg: #f3f4f6;
            --code-bg: #282c34;
            --border-color: #e5e7eb;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            margin: 0;
            display: flex;
            min-height: 100vh;
        }

        /* 侧边栏导航 */
        nav {
            width: 260px;
            background-color: var(--sidebar-bg);
            padding: 2rem 1rem;
            position: fixed;
            height: 100vh;
            overflow-y: auto;
            border-right: 1px solid var(--border-color);
            display: none; /* 移动端默认隐藏 */
        }

        nav ul {
            list-style: none;
            padding: 0;
        }

        nav li {
            margin-bottom: 0.8rem;
        }

        nav a {
            text-decoration: none;
            color: #4b5563;
            font-size: 0.95rem;
            transition: color 0.2s;
        }

        nav a:hover, nav a.active {
            color: var(--primary-color);
            font-weight: 600;
        }

        nav h3 {
            font-size: 0.85rem;
            text-transform: uppercase;
            color: #9ca3af;
            margin-bottom: 1rem;
            letter-spacing: 0.05em;
        }

        /* 主内容区 */
        main {
            flex: 1;
            padding: 2rem 4rem;
            max-width: 1000px;
            margin-left: 260px; /* 留出侧边栏宽度 */
        }

        h1 { font-size: 2.25rem; margin-bottom: 1.5rem; border-bottom: 1px solid var(--border-color); padding-bottom: 1rem; }
        h2 { font-size: 1.75rem; margin-top: 3rem; margin-bottom: 1rem; color: #111827; }
        h3 { font-size: 1.4rem; margin-top: 2rem; margin-bottom: 0.8rem; color: #374151; }
        h4 { font-size: 1.1rem; margin-top: 1.5rem; font-weight: 600; }

        p { margin-bottom: 1rem; }

        ul, ol { margin-bottom: 1rem; padding-left: 1.5rem; }
        li { margin-bottom: 0.5rem; }

        /* 代码块样式 */
        pre {
            background-color: var(--code-bg);
            border-radius: 8px;
            padding: 1rem;
            overflow-x: auto;
            margin: 1.5rem 0;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
        }
        
        code {
            font-family: "Fira Code", Consolas, Monaco, monospace;
            font-size: 0.9rem;
        }

        /* 引用块 */
        blockquote {
            border-left: 4px solid var(--primary-color);
            background-color: #eff6ff;
            margin: 1.5rem 0;
            padding: 1rem;
            border-radius: 0 8px 8px 0;
        }

        /* Mermaid 图表容器 */
        .mermaid-container {
            background: #fff;
            padding: 1rem;
            border: 1px solid var(--border-color);
            border-radius: 8px;
            margin: 2rem 0;
            text-align: center;
        }

        /* 响应式设计 */
        @media (min-width: 1024px) {
            nav { display: block; }
        }

        @media (max-width: 1023px) {
            main { margin-left: 0; padding: 1.5rem; }
            nav { display: none; }
        }
    </style>
</head>
<body>

    <!-- 侧边栏目录 -->
    <nav>
        <h3>目录</h3>
        <ul>
            <li><a href="#overview">1. 概述</a></li>
            <li><a href="#architecture">2. 总体架构图</a></li>
            <li><a href="#pipeline-data">3. 离线数据处理流程</a></li>
            <ul>
                <li><a href="#parsing">3.1 文档解析与切分</a></li>
                <li><a href="#extraction">3.2 LLM 信息抽取</a></li>
                <li><a href="#normalization">3.3 实体归一化 (核心)</a></li>
                <li><a href="#construction">3.4 图谱构建与合并</a></li>
            </ul>
            <li><a href="#pipeline-query">4. 在线问答处理流程</a></li>
            <li><a href="#analysis">5. 方案优缺点分析</a></li>
        </ul>
    </nav>

    <!-- 主内容 -->
    <main>
        <header>
            <h1>Graph-RAG 系统技术方案--王欣鑫</h1>
            <p><strong>版本：</strong> v1.0 | <strong>状态：</strong> Draft</p>
        </header>

        <section id="overview">
            <h2>1. 概述</h2>
            <p>本方案旨在构建一个结合知识图谱（Knowledge Graph, KG）与大语言模型（LLM）的 RAG 系统。通过将非结构化文档转化为“实体-关系”的图谱结构，解决传统向量检索在处理复杂逻辑、多跳推理及全局理解上的不足。</p>
            <blockquote>
                <strong>核心理念：</strong><br>
                • <strong>文档即图谱：</strong>利用 LLM 提取文档中的实体与关系。<br>
                • <strong>图文关联：</strong>图谱中的节点（实体）与原始文档切片（Chunk）保持索引关联。<br>
                • <strong>混合检索：</strong>查询时通过图谱的跳数（Hop）扩展上下文，而非仅靠关键词匹配。
            </blockquote>
        </section>

        <section id="architecture">
            <h2>2. 总体架构图</h2>
            <div class="mermaid-container">
                <div class="mermaid">
graph TD
    subgraph "离线数据处理流程 (Data Pipeline)"
        A[原始文档 PDF/Word/MD] --> B(文档解析 Parsing)
        B --> C(文本切分 Chunking)
        C --> D{LLM 信息抽取}
        D -->|提取实体| E[实体 Entity]
        D -->|提取关系| F[关系 Relation]
        E & F --> G(实体归一化 Normalization)
        G --> H(图谱构建 Graph Construction)
        H --> I[(图数据库 Neo4j)]
        C --> J[(向量/文本数据库)]
        I -.->|关联 chunk_id| J
    end

    subgraph "在线问答处理流程 (Query Pipeline)"
        U[用户提问] --> V(查询理解/实体识别)
        V --> W(图谱检索 & 多跳扩展)
        W --> X(获取关联 Chunk 内容)
        X --> Y(上下文重组 Context Merge)
        Y --> Z(LLM 答案生成)
        Z --> Ans[最终回答]
    end
                </div>
            </div>
        </section>

        <section id="pipeline-data">
            <h2>3. 离线数据处理流程</h2>
            <p>此流程负责将非结构化数据转化为结构化知识并入库，是 Graph-RAG 的基石。</p>

            <h3 id="parsing">3.1 文档解析与切分 (Parsing & Chunking)</h3>
            <ul>
                <li><strong>输入：</strong> PDF, Word, Markdown, HTML 等格式文件。</li>
                <li><strong>处理逻辑：</strong>
                    <ol>
                        <li><strong>加载 (Loader)：</strong> 使用商汤科技的 autopdf 等文档解析工具将不同格式文件转换为 Markdown 格式。</li>
                        <li><strong>切分 (Splitter)：</strong> 采用混合切分策略：
                            <ul>
                                <li>基于 Markdown 标题的结构化切分。</li>
                                <li>特殊内容保护（表格、图片不打碎）。</li>
                                <li>递归字符切分（Recursive Character Splitting）处理长文本。</li>
                                <li>Token 级别切分，确保符合 LLM 窗口限制。</li>
                            </ul>
                        </li>
                        <li><strong>索引化：</strong> 为每个切片生成唯一的 <code>chunk_id</code>，作为后续图谱回溯原文的锚点。</li>
                    </ol>
                </li>
            </ul>

            <h3 id="extraction">3.2 LLM 信息抽取 (LLM-based Extraction)</h3>
            <p>直接利用 LLM 的理解能力，从 Chunk 中提取结构化数据。在此阶段，我们需要引入<strong>类型约束</strong>以保证数据质量。</p>
            
            <h4>核心代码实现：实体抽取与类型约束</h4>
            <pre><code class="language-python">class Config:
    # 1. 定义类型列表 (业务强约束)
    ALLOWED_TYPES = [
        'Person', 'Organization', 'Location', 
        'Event', 'Concept', 'Document', 'Other'
    ]

def extract_entities_from_chunk(text_chunk):
    """
    利用 LLM 从文本块中抽取实体，并强制约束类型。
    """
    system_prompt = f"""
    你是一个知识图谱实体抽取专家。请从文本中提取实体。
    
    【类型约束】
    实体的类型必须严格属于以下列表：{Config.ALLOWED_TYPES}。
    如果实体不属于列表中的任何一项，请归类为 'Other' 或列表中语义最接近的项。
    
    【输出格式】
    JSON List: [{{ "name": "实体名", "type": "类型", "context": "所在的上下文句子" }}]
    """
    
    user_prompt = f"文本内容：{text_chunk}"
    
    # 调用 LLM (伪代码)
    raw_entities = call_llm(system_prompt, user_prompt)
    
    # 预处理：计算 Embedding，为后续归一化做准备
    processed_entities = []
    for e in raw_entities:
        # 混合名称和上下文做向量，增加区分度
        e['embedding'] = get_embedding(e['name'] + " " + e['context']) 
        processed_entities.append(e)
        
    return processed_entities</code></pre>

            <h3 id="normalization">3.3 实体归一化 (Normalization)</h3>
            <p>这是解决“同名异义”或“异名同义”的关键步骤。我们采用多级漏斗机制：<strong>字面匹配 -> 语义相似度 -> LLM 深度裁决</strong>。</p>

            <h4>核心代码实现：归一化判定逻辑</h4>
            <pre><code class="language-python"># 阈值常量定义
THRESHOLD_SEMANTIC_HIGH = 0.92  # 语义极高：确信是同一个意思
THRESHOLD_SEMANTIC_LOW = 0.60   # 语义过低：确信没关系
THRESHOLD_STRING_SAFE = 0.70    # 字面相似：拼写微调或包含关系
THRESHOLD_STRING_EXACT = 1.0    # 字面完全一致

def is_same_entity(new_entity, existing_entity):
    """
    判断两个实体是否为同一个，并返回判定结果。
    """
    candidate_name = new_entity['name']
    target_name = existing_entity['name']
    
    # 1. [极速通道] 字面完全一致 -> 视为同一实体
    if candidate_name.lower() == target_name.lower():
        return True

    # 计算分数
    sem_score = cosine_similarity(new_entity['embedding'], existing_entity['embedding'])
    str_score = levenshtein_ratio(candidate_name, target_name)

    # 2. [快速拒绝通道] 语义完全不相关 -> 拒绝
    if sem_score < THRESHOLD_SEMANTIC_LOW:
        return False

    # 3. [快速通过通道] 语义极高 + 字面较像 -> 通过
    if sem_score > THRESHOLD_SEMANTIC_HIGH and str_score > THRESHOLD_STRING_SAFE:
        # 额外检查：如果类型完全冲突（如 Person vs Location），即使语义像也不能通过
        if new_entity['type'] != existing_entity['type'] and \
           new_entity['type'] != 'Other' and existing_entity['type'] != 'Other':
             pass # 类型强冲突，转入 LLM 裁决
        else:
            return True

    # 4. [LLM 裁判通道] 处理“中间地带” (如别名、包含关系、版本差异)
    print(f"LLM 裁决: {candidate_name} vs {target_name}")
    return llm_judge_is_same(new_entity, existing_entity)

def llm_judge_is_same(entity_a, entity_b):
    """
    LLM 深度裁决 Prompt
    """
    prompt = f"""
    判断实体 A 和 实体 B 在知识图谱中是否应合并为【同一个】节点。
    实体 A: {entity_a['name']} (类型: {entity_a['type']}, 上下文: {entity_a['context']})
    实体 B: {entity_b['name']} (类型: {entity_b['type']}, 上下文: {entity_b['context']})
    
    判决逻辑：
    1. [别名/全称] 如 "Elon Musk" 和 "Musk" -> True
    2. [版本/型号] 如 "iPhone 14" 和 "iPhone 15" -> False
    3. [包含/从属] 如 "阿里云" 和 "阿里集团" -> False
    4. [不同指代] 如 "苹果(水果)" 和 "苹果(公司)" -> False
    
    返回 JSON: {{"is_same": boolean, "reason": "string"}}
    """
    return call_llm(prompt)['is_same']</code></pre>

            <h3 id="construction">3.4 图谱构建与合并 (Graph Construction & Merging)</h3>
            <p>在判定实体一致性后，需要执行合并操作，并进行<strong>类型对齐</strong>，确保图谱 Schema 的整洁。</p>

            <h4>核心代码实现：合并与类型对齐</h4>
            <pre><code class="language-python">def process_and_merge_entity(new_entity, knowledge_graph):
    """
    主流程：将新抽取的实体 归一化 并 写入图谱
    """
    # 1. 候选召回：从图谱中检索 Top-K 相似实体
    candidates = knowledge_graph.search_candidates(
        query_vec=new_entity['embedding'], top_k=5
    )
    
    matched_entity = None
    # 2. 遍历候选者进行判定
    for candidate in candidates:
        if is_same_entity(new_entity, candidate):
            matched_entity = candidate
            break 
    
    # 3. 执行合并策略
    if matched_entity:
        final_id = matched_entity['id']
        
        # 类型对齐：优先保留更准确的类型
        final_type = align_types(matched_entity['type'], new_entity['type'])
        
        if final_type != matched_entity['type']:
            knowledge_graph.update_node_type(final_id, final_type)
            
        # (可选) 别名融合
        knowledge_graph.add_alias(final_id, new_entity['name'])
    else:
        # 未命中 -> 创建新节点
        final_id = knowledge_graph.create_node(
            name=new_entity['name'], 
            type=new_entity['type'], 
            embedding=new_entity['embedding']
        )
        
    return final_id

def align_types(existing_type, new_type):
    """
    类型对齐逻辑：具体类型 > 抽象类型 > Other
    """
    if existing_type == new_type: return existing_type
    
    high_priority_types = ['Person', 'Organization', 'Location', 'Event']
    
    # 如果现有的是 Other/Concept，新的是具体类型 -> 更新为新的
    if existing_type in ['Other', 'Concept'] and new_type in high_priority_types:
        return new_type
        
    # 默认保持现有
    return existing_type</code></pre>
        </section>

        <section id="pipeline-query">
            <h2>4. 在线问答处理流程</h2>
            <p>此流程负责利用构建好的图谱回答用户问题。</p>
            <ol>
                <li><strong>问题理解与实体提取：</strong>
                    <ul>
                        <li>输入：用户 Query（例如：“Weknora 和 RAGFlow 有什么区别？”）。</li>
                        <li>处理：利用 LLM 提取关键实体（如 "Weknora", "RAGFlow"）作为图谱检索的“入口节点”。</li>
                    </ul>
                </li>
                <li><strong>图谱检索与扩展 (Graph Traversal)：</strong>
                    <ul>
                        <li>定位：在 Neo4j 中匹配入口节点。</li>
                        <li>扩展 (1-N Hop)：查询邻居节点。Cypher 示例：<code>MATCH (n)-[r]-(m) WHERE n.name IN [...] RETURN n, r, m</code></li>
                        <li>路径发现：查找实体间的最短路径。</li>
                    </ul>
                </li>
                <li><strong>上下文召回 (Context Retrieval)：</strong>
                    <ul>
                        <li>获取检索到的节点和边中存储的 <code>chunk_id</code>。</li>
                        <li>从文本数据库召回原始文本切片。</li>
                        <li><strong>优势：</strong> 能召回“字面上不相似但逻辑上强相关”的内容。</li>
                    </ul>
                </li>
                <li><strong>答案生成 (Answer Generation)：</strong>
                    <ul>
                        <li>将图谱结构信息（摘要）和原始文本切片（详情）拼接到 System Prompt。</li>
                        <li>LLM 生成最终答案并标注来源。</li>
                    </ul>
                </li>
            </ol>
        </section>

        <section id="analysis">
            <h2>5. 方案优缺点分析</h2>
            <div style="display: flex; gap: 2rem; flex-wrap: wrap;">
                <div style="flex: 1; min-width: 300px;">
                    <h3>✅ 优点</h3>
                    <ul>
                        <li><strong>结构化认知：</strong> 显性展示实体间的逻辑关系。</li>
                        <li><strong>多跳推理：</strong> 解决跨文档片段的复杂推理问题（A->B->C）。</li>
                        <li><strong>全局视角：</strong> 通过实体归一化，聚合分散信息形成完整画像。</li>
                    </ul>
                </div>
                <div style="flex: 1; min-width: 300px;">
                    <h3>⚠️ 挑战</h3>
                    <ul>
                        <li><strong>构建成本高：</strong> LLM 抽取消耗大量 Token，速度较慢。</li>
                        <li><strong>归一化难度：</strong> 实体对齐是业界难题，需精细调节阈值。</li>
                        <li><strong>Schema 设计：</strong> 需预定义合理的 Ontology，防止图谱过稀或过密。</li>
                    </ul>
                </div>
            </div>
        </section>

        <footer>
            <p style="text-align: center; margin-top: 4rem; color: #6b7280; font-size: 0.9rem;">
                Generated for Graph-RAG Implementation Guide
            </p>
        </footer>
    </main>

</body>
</html>